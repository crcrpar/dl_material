{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデルの学習について\n",
    "「モデルの学習においてどのようにパラメータを更新するか」ですが、__誤差逆伝播法__をというアルゴリズムでパラメータを更新します。誤差逆伝播法を説明するために、シンプルなフィードフォーワードネットワークでイメージを説明したいと思います。\n",
    "図においてユニット間の矢印が\\は重み$w$（weight）を表し、円の中の文字は各ユニットの名称とします。また、活性化関数はactivationの頭文字をとって$a(\\cdot)$で表します。図において、$o_1$はユニット$u_1, u_2$の重み付き和で$o_1 = w_{11}u_1 + w_{21}u_2$で計算できます。\n",
    "同様に、$u_1 = w_{11}x_1 + w_{21}x_2 + w_{31}u_3 + w_{41}u_4 = \\sum_{i=1}^4 w_{i1}x_i  = \\mathbf{W}\\boldsymbol{x}$とまとめられます。\n",
    "よって、$\\boldsymbol{y} = a(o_1) = a(a(\\mathbf{W}_2\\boldsymbol{u})) = a(a(\\mathbf{W}_2a(\\mathbf{W}_1\\boldsymbol{x}))$とreurssiveに表せます。\n",
    "\n",
    "\n",
    "出力を$\\boldsymbol{y}$、正解を$\\hat{\\boldsymbol{y}}$とすると、誤差は誤差関数\n",
    "$L(\\hat{\\boldsymbol{y}}, \\boldsymbol{y})$で計算されます。\n",
    "誤差逆伝播法は$\\dfrac{\\partial L(\\hat{\\boldsymbol{y}}, \\boldsymbol{y})}{\\partial w_{ij}} = (\\hat{\\boldsymbol{y}} -  \\boldsymbol{y})^{\\top} \\dfrac{\\partial \\hat{\\boldsymbol{y}}}{\\partial w_{ij}}$をベースに重みを更新します。\n",
    "$l$層目の更新は$l+1$層目の値をもとにchain ruleを用いて計算します。\n",
    "\n",
    "微分と聞いて萎えた人もいるかもしれませんが、ご安心ください。フレームワークが自動で計算してくれます。\n",
    "では、早速、フレームワークを使ってライブラリでの変数の使い方、自動微分を確認しましょう。\n",
    "\n",
    "各セルはshift + enterで実行できます。\n",
    "\n",
    "```\n",
    "import torch\n",
    "x = torch.Tensor(5, 3)\n",
    "```\n",
    "を下のセルで実行してみましょう。\n",
    "\n",
    "また、`%%bash`を冒頭に書いたセルではbashコマンドを実行できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 152\n",
      "-rw-r--r--  1 staff   9.1K May  6 17:53 0_introduction_of _learning.ipynb\n",
      "-rw-r--r--@ 1 staff   6.3K Apr 23 17:16 autograd_tutorial.ipynb\n",
      "-rw-r--r--@ 1 staff   6.3K Apr 23 17:16 autograd_tutorial.ipynb.1\n",
      "-rw-r--r--@ 1 staff   6.3K Apr 23 17:16 autograd_tutorial.ipynb.2\n",
      "-rw-r--r--@ 1 staff   6.3K Apr 23 17:16 autograd_tutorial.ipynb.3\n",
      "-rw-r--r--@ 1 staff   7.1K Apr 23 17:16 tensor_tutorial.ipynb\n",
      "-rw-r--r--@ 1 staff   7.1K Apr 23 17:16 tensor_tutorial.ipynb.1\n",
      "-rw-r--r--@ 1 staff   7.1K Apr 23 17:16 tensor_tutorial.ipynb.2\n",
      "-rw-r--r--@ 1 staff   7.1K Apr 23 17:16 tensor_tutorial.ipynb.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2017-05-06 18:02:57--  http://pytorch.org/tutorials/_downloads/tensor_tutorial.ipynb\n",
      "Resolving pytorch.org... 192.30.252.153\n",
      "Connecting to pytorch.org|192.30.252.153|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7315 (7.1K) [application/octet-stream]\n",
      "Saving to: ‘tensor_tutorial.ipynb.3’\n",
      "\n",
      "     0K .......                                               100% 2.42M=0.003s\n",
      "\n",
      "2017-05-06 18:02:58 (2.42 MB/s) - ‘tensor_tutorial.ipynb.3’ saved [7315/7315]\n",
      "\n",
      "--2017-05-06 18:02:58--  http://pytorch.org/tutorials/_downloads/autograd_tutorial.ipynb\n",
      "Resolving pytorch.org... 192.30.252.153\n",
      "Connecting to pytorch.org|192.30.252.153|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6449 (6.3K) [application/octet-stream]\n",
      "Saving to: ‘autograd_tutorial.ipynb.3’\n",
      "\n",
      "     0K ......                                                100% 61.5M=0s\n",
      "\n",
      "2017-05-06 18:02:58 (61.5 MB/s) - ‘autograd_tutorial.ipynb.3’ saved [6449/6449]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "wget http://pytorch.org/tutorials/_downloads/tensor_tutorial.ipynb\n",
    "wget http://pytorch.org/tutorials/_downloads/autograd_tutorial.ipynb\n",
    "\n",
    "ls -g -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: \n",
      " 0.0000e+00 -1.5846e+29  5.4353e-30\n",
      "-1.0845e-19  6.1630e-33  1.4013e-45\n",
      " 4.1412e-33  1.4013e-45  8.0392e-33\n",
      " 1.4013e-45  5.8693e-33  1.4013e-45\n",
      " 5.4054e-33  1.4013e-45  5.3207e-33\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.Tensor(5, 3)\n",
    "\n",
    "print('x: {}'.format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.5246  0.8948  0.8550\n",
      " 0.0660  0.7591  0.6264\n",
      " 0.9002  0.4140  0.1190\n",
      " 0.6253  0.7102  0.8339\n",
      " 0.7086  0.9752  0.2164\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1.2505  1.2449  0.8633\n",
      " 0.4939  1.4918  1.5744\n",
      " 1.2365  1.0999  0.8417\n",
      " 1.1553  1.1960  1.3604\n",
      " 1.4752  1.9528  0.4506\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5, 3)\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1.2505  1.2449  0.8633\n",
      " 0.4939  1.4918  1.5744\n",
      " 1.2365  1.0999  0.8417\n",
      " 1.1553  1.1960  1.3604\n",
      " 1.4752  1.9528  0.4506\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1.2505  1.2449  0.8633\n",
      " 0.4939  1.4918  1.5744\n",
      " 1.2365  1.0999  0.8417\n",
      " 1.1553  1.1960  1.3604\n",
      " 1.4752  1.9528  0.4506\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n",
      "\n",
      " 1.2505  1.2449  0.8633\n",
      " 0.4939  1.4918  1.5744\n",
      " 1.2365  1.0999  0.8417\n",
      " 1.1553  1.1960  1.3604\n",
      " 1.4752  1.9528  0.4506\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = torch.Tensor(5, 3)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)\n",
    "print(y.add_(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.8948\n",
      " 0.7591\n",
      " 0.4140\n",
      " 0.7102\n",
      " 0.9752\n",
      "[torch.FloatTensor of size 5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(x[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.FloatTensor of size 5]\n",
      "\n",
      "<class 'torch.FloatTensor'>\n",
      "[ 1.  1.  1.  1.  1.]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)\n",
    "print(type(a))\n",
    "print(a.numpy())\n",
    "print(type(a.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'torch.DoubleTensor'>\n",
      "\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.DoubleTensor of size 5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "print(type(a))\n",
    "print(type(torch.from_numpy(a)))\n",
    "print(torch.from_numpy(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 自動微分\n",
    "多くのフレームワークでは変数のインスタンスが、入力となるデータ（直接変更を加えることが多いデータ）の他に、\n",
    "その変数の勾配とどのクラスで作成されたかを保持することが多いです。\n",
    "中には、学習時以外で勾配（ロス）を計算する無駄を省くために、学習中かどうかのフラグを持つこともあります。\n",
    "PyTorchでは変数は`Variable`クラスを用います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1  1\n",
      " 1  1\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.ones(2, 2), requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 3  3\n",
      " 3  3\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.autograd._functions.basic_ops.AddConstant object at 0x10d323470>\n"
     ]
    }
   ],
   "source": [
    "print(y.creator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z: Variable containing:\n",
      " 27  27\n",
      " 27  27\n",
      "[torch.FloatTensor of size 2x2]\n",
      ", out: Variable containing:\n",
      " 27\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "print('z: {}, out: {}'.format(z, out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでは自動微分が実際に動作していることを確認するために、強引に誤差逆伝播を行います。\n",
    "多くのフレームワークで、モデルの出力や、誤差を表す変数で`variable.backward()`を実行することで勾配が伝播しますが、\n",
    "この段階ではまだパラメータの更新は行われません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 4.5000  4.5000\n",
      " 4.5000  4.5000\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
